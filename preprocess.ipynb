{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parse_vector(s):\n",
    "    s = s.replace('[', '')\n",
    "    s = s.replace(']', '')\n",
    "    s = s.strip()\n",
    "    l = map(float, s.split(' '))\n",
    "    return l\n",
    "\n",
    "def save_dataframe(path, df):\n",
    "    path_l = path.split('/')\n",
    "    file_name = path_l[-1]\n",
    "    del path_l[-1]\n",
    "    \n",
    "    if not os.path.exists('/'.join(path_l)):\n",
    "        os.makedirs('/'.join(path_l))\n",
    "    df.to_pickle(path)\n",
    "    print 'file saved - {}'.format(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TRAIN FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'train_db/'\n",
    "TEST_PATH = 'test_db/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52284/52284 [00:05<00:00, 9875.19it/s] \n"
     ]
    }
   ],
   "source": [
    "# convert all txt files to pandas DataFrame\n",
    "\n",
    "train_files = sorted(listdir(TRAIN_PATH))\n",
    "\n",
    "vecs = []\n",
    "person_ids = []\n",
    "\n",
    "for txt in tqdm(train_files):\n",
    "    with open('{}{}'.format(TRAIN_PATH, txt), 'r') as f:\n",
    "        content = f.read()\n",
    "        parsed = parse_vector(content)\n",
    "        person_id = txt[:4]\n",
    "    vecs.append(parsed)\n",
    "    person_ids.append(person_id)\n",
    "        \n",
    "df = pd.DataFrame({'vec':vecs, 'person_id': person_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52284 entries, 0 to 52283\n",
      "Data columns (total 3 columns):\n",
      "is_duplicate    52284 non-null int64\n",
      "vec1            52284 non-null object\n",
      "vec2            52284 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "shuffled: len - 52284, 0 - 52027, 1 - 257\n"
     ]
    }
   ],
   "source": [
    "# random shuffle two parts of raw_train.h5 in a loop and compare each with each\n",
    "\n",
    "full_vec1 = []\n",
    "full_vec2 = []\n",
    "is_duplicate = []\n",
    "person_id1 = []\n",
    "person_id2 = []\n",
    "for i in range(2):\n",
    "    left = df.sample(frac=0.5, replace=False)\n",
    "    right = df.sample(frac=0.5, replace=False)\n",
    "    vec1 = left['vec'].values\n",
    "    vec2 = right['vec'].values\n",
    "    person_id1 = left['person_id'].values\n",
    "    person_id2 = right['person_id'].values\n",
    "    \n",
    "    for i in range(len(person_id1)):\n",
    "        if person_id1[i] == person_id2[i]:\n",
    "            is_duplicate.append(1)\n",
    "        else:\n",
    "            is_duplicate.append(0)\n",
    "\n",
    "    full_vec1 += list(vec1)\n",
    "    full_vec2 += list(vec2)\n",
    "\n",
    "shuffled = pd.DataFrame({'vec1': full_vec1, 'vec2': full_vec2, \n",
    "                         'is_duplicate': is_duplicate})\n",
    "print shuffled.info()\n",
    "print 'shuffled: len - {}, 0 - {}, 1 - {}'.format(len(shuffled), len(shuffled[shuffled.is_duplicate == 0]), \n",
    "                                                  len(shuffled[shuffled.is_duplicate == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517020 entries, 0 to 517019\n",
      "Data columns (total 3 columns):\n",
      "is_duplicate    517020 non-null int64\n",
      "vec1            517020 non-null object\n",
      "vec2            517020 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 11.8+ MB\n",
      "None\n",
      "duplicates: len - 517020, 0 - 0, 1 - 517020\n"
     ]
    }
   ],
   "source": [
    "# create pairs of duplicates\n",
    "\n",
    "full_vec1 = []\n",
    "full_vec2 = []\n",
    "for i in range(10):\n",
    "    for i in df.person_id.unique():\n",
    "        one_person = df[df.person_id == i]\n",
    "        left = one_person.sample(frac=0.99, replace=True)\n",
    "        right = one_person.sample(frac=0.99, replace=True)\n",
    "\n",
    "        vec1 = left['vec'].values\n",
    "        vec2 = right['vec'].values\n",
    "\n",
    "        full_vec1 += list(vec1)\n",
    "        full_vec2 += list(vec2)\n",
    "\n",
    "is_duplicate = [1 for i in xrange(len(full_vec1))]\n",
    "duplicates = pd.DataFrame({'vec1': full_vec1, 'vec2': full_vec2, \n",
    "                           'is_duplicate': is_duplicate})  \n",
    "print duplicates.info()\n",
    "print 'duplicates: len - {}, 0 - {}, 1 - {}'.format(len(duplicates), len(duplicates[duplicates.is_duplicate == 0]), \n",
    "                                        len(duplicates[duplicates.is_duplicate == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569304 entries, 0 to 569303\n",
      "Data columns (total 3 columns):\n",
      "is_duplicate    569304 non-null int64\n",
      "vec1            569304 non-null object\n",
      "vec2            569304 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 13.0+ MB\n",
      "None\n",
      "len - 569304, 0 - 52027, 1 - 517277\n"
     ]
    }
   ],
   "source": [
    "# create dataset where target distribution is equal\n",
    "\n",
    "full = pd.concat([shuffled, duplicates], ignore_index=True)\n",
    "\n",
    "print full.info()\n",
    "print 'len - {}, 0 - {}, 1 - {}'.format(len(full), len(full[full.is_duplicate == 0]), \n",
    "                                        len(full[full.is_duplicate == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved - dataset/train/raw_train.h5\n",
      "file saved - dataset/train/shuffled+duplicates.h5\n",
      "file saved - dataset/train/shuffled_min.h5\n"
     ]
    }
   ],
   "source": [
    "save_dataframe('dataset/train/raw_train.h5', df)\n",
    "save_dataframe('dataset/train/shuffled+duplicates.h5', full)\n",
    "save_dataframe('dataset/train/shuffled_min.h5', shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TEST FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 953/953 [00:00<00:00, 12107.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 953 entries, 0 to 952\n",
      "Data columns (total 2 columns):\n",
      "person_id    953 non-null object\n",
      "vec          953 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.0+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_files = sorted(listdir(TEST_PATH))\n",
    "\n",
    "vecs = []\n",
    "person_ids = []\n",
    "\n",
    "for txt in tqdm(test_files):\n",
    "    with open('{}{}'.format(TEST_PATH, txt), 'r') as f:\n",
    "        content = f.read()\n",
    "        parsed = parse_vector(content)\n",
    "        person_id = txt[:4]\n",
    "    vecs.append(parsed)\n",
    "    person_ids.append(person_id)\n",
    "        \n",
    "raw_test = pd.DataFrame({'vec':vecs, 'person_id': person_ids})\n",
    "print raw_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 953/953 [00:00<00:00, 1125.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 907256 entries, 0 to 907255\n",
      "Data columns (total 3 columns):\n",
      "is_duplicate    907256 non-null int64\n",
      "vec1            907256 non-null object\n",
      "vec2            907256 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 20.8+ MB\n",
      "None\n",
      "len - 907256, 0 - 899640, 1 - 7616\n"
     ]
    }
   ],
   "source": [
    "vec1 = []\n",
    "vec2 = []\n",
    "is_duplicate = []\n",
    "\n",
    "for i in tqdm(range(len(raw_test))):\n",
    "    current_vec = raw_test.vec[i]\n",
    "    current_person = raw_test.person_id[i]\n",
    "    \n",
    "    exception = raw_test.index.isin([i])\n",
    "    sample = raw_test[~exception]\n",
    "    vecs = sample['vec'].values\n",
    "    persons = sample['person_id'].values\n",
    "    \n",
    "    for person in zip(persons, vecs):\n",
    "        vec1.append(current_vec)\n",
    "        vec2.append(person[1])\n",
    "        if person[0] == current_person:\n",
    "            is_duplicate.append(1)\n",
    "        else:\n",
    "            is_duplicate.append(0)\n",
    "            \n",
    "\n",
    "test_df = pd.DataFrame({'vec1':vec1, 'vec2': vec2, 'is_duplicate': is_duplicate})\n",
    "print test_df.info()\n",
    "print 'len - {}, 0 - {}, 1 - {}'.format(len(test_df), len(test_df[test_df.is_duplicate == 0]), \n",
    "                                        len(test_df[test_df.is_duplicate == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved - dataset/test/raw_test.h5\n",
      "file saved - dataset/test/test.h5\n"
     ]
    }
   ],
   "source": [
    "save_dataframe('dataset/test/raw_test.h5', raw_test)\n",
    "save_dataframe('dataset/test/test.h5', test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
